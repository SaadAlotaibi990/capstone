{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement :\n",
    "Predicting the purchase offer to which a possible higher level of response or user actions like ‘offer received’, ‘offer viewed’, ‘transaction’ and  ‘offer completed’ can be achieved based on the demographic attributes of the customer and other attributes of the companies purchase offers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries & loading datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.head(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Accessing and Cleaning :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Portfolio Data\n",
    "\n",
    "#### Dataset overview :\n",
    "\n",
    "**portfolio.json**\n",
    "\n",
    "- id (string) - offer id\n",
    "- offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "- difficulty (int) - minimum required spend to complete an offer\n",
    "- reward (int) - reward given for completing an offer\n",
    "- duration (int) - time for offer to be open, in days\n",
    "- channels (list of strings)\n",
    "\n",
    " There are three types of offers that can be sent: `buy-one-get-one (BOGO)`, `discount`, and `informational`.\n",
    "- In a BOGO offer, a user needs to spend a certain amount to get a reward equal to that threshold amount. \n",
    "- In a discount, a user gains a reward equal to a fraction of the amount spent.\n",
    "- In an informational offer, there is no reward, but neither is there a requisite amount that the user is expected to spend. \n",
    "\n",
    "Offers can be delivered via multiple channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio['channels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Data Cleaning\n",
    "\n",
    "- create a copy of the original dataframe for further implementation .\n",
    "- convert the column 'Channels' into 4 different channel on the basis of different types of channel .\n",
    "- rename the column name from 'ID' to 'offer_id' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = portfolio.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(df1.channels.apply(pd.Series).stack()).sum(level=0)\n",
    "df1 = pd.concat([df1, dummy], axis=1)\n",
    "df1 = df1.drop(columns='channels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns={'id':'offer_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Profile Data\n",
    "#### Dataset overview :\n",
    "\n",
    "**profile.json**\n",
    "\n",
    "- age (int) - age of the customer\n",
    "- became_member_on (int) - date when customer created an app account\n",
    "- gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "- id (str) - customer id\n",
    "- income (float) - customer's income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Data Cleaning\n",
    "- create a copy of the original dataframe for further implementation .\n",
    "- convert the datatype of 'became_member_on' column and sort the date into proper format .\n",
    "- change the column name from 'ID' to 'customer_id' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = profile.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['became_member_on'] = pd.to_datetime(df2['became_member_on'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={'id':'customer_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df2.became_member_on[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transcript Data\n",
    "#### Dataset overview :\n",
    "\n",
    "**transcript.json**\n",
    "\n",
    "- event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "- person (str) - customer id\n",
    "- time (int) - time in hours since start of test. The data begins at time t=0\n",
    "- value - (dict of strings) - either an offer id or transaction amount depending on the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['value'].value_counts()   \n",
    "# the error occur because Column Vlaue contains dictonary in each row ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['event'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['event'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Data Cleaning\n",
    "- create a copy of the original dataframe for further implementation .\n",
    "- change the column name from 'person' to 'customer_id' .\n",
    "- convert the column 'Event' into 4 different columns on the basis of different types of event .\n",
    "- convert the column 'Values' into 2 different column  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = transcript.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.rename(columns={'person':'customer_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['event'] = df3['event'].str.replace(' ', '-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(df3['event'])\n",
    "df3 = pd.concat([df3, dummy], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['offer_id'] = [[*i.values()][0]if [*i.keys()][0] in ['offer id','offer_id'] else None for i in df3.value]\n",
    "df3['amount'] = [np.round([*i.values()][0], decimals=2)if [*i.keys()][0] == 'amount' else None for i in df3.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop(columns='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Data Cleaning :\n",
    "\n",
    "- Concatenate all the three dataset together .\n",
    "- Fixed the Offer_ids .\n",
    "- fixed even_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p = pd.merge(df3, df2, on='customer_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(t_p, df1, on='offer_id', how='left')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_id = df['offer_id'].unique()\n",
    "offer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_dict = pd.Series(offer_id ).to_dict()\n",
    "offer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_dict = dict([(value, key) for key, value in offer_dict.items()]) \n",
    "offer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offer_id'] = df['offer_id'].map(offer_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offer_id'] = df['offer_id'].replace(1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offer_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_ids = df['event'].unique()\n",
    "event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = pd.Series(event_ids).to_dict()\n",
    "event_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = dict([(value, key) for key, value in event_dict.items()]) \n",
    "event_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map event_ids to the encoded event ids\n",
    "df['event_id'] = df['event'].map(event_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Data Visualization :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.age.hist(bins = 30)\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Age Group Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation :\n",
    "\n",
    "- Outlier is present Age > 115 is present is high amount , which does not make sense .\n",
    "- Average Aged user is middle age ie. around 50-62 years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.income.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.income.hist(bins = 30);\n",
    "plt.xlabel('Income Range')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Income Range Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation :\n",
    "\n",
    "- Average income user is middle income group ie. 65000-70000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_proportion  = data.gender.value_counts()[0] / data.shape[0]*100\n",
    "female_proportion = data.gender.value_counts()[1] / data.shape[0]*100\n",
    "others_proportion = data.gender.value_counts()[2] / data.shape[0]*100\n",
    "\n",
    "male_proportion ,female_proportion ,others_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.gender.value_counts()\n",
    "ax.plot(kind='bar')\n",
    "plt.ylabel('Number of People')\n",
    "plt.xlabel('Gender')\n",
    "plt.title('Gender Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation :\n",
    "\n",
    "- males are more than 50 percent of users ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_received = data[data['offer-received'] == 1].offer_type.value_counts()\n",
    "offer_viewed = data[data['offer-viewed'] == 1].offer_type.value_counts()\n",
    "offer_completed = data[data['offer-completed'] == 1].offer_type.value_counts()\n",
    "\n",
    "offer_received , offer_viewed , offer_completed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(131)\n",
    "offer_received = data[data['offer-received'] == 1].offer_type.value_counts()\n",
    "offer_received.plot(kind='bar', figsize=(15,5))\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Offer Type')\n",
    "plt.title('Offer received with Offer Type ');\n",
    "\n",
    "plt.subplot(132)\n",
    "offer_viewed = data[data['offer-viewed'] == 1].offer_type.value_counts()\n",
    "offer_viewed.plot(kind='bar' , figsize=(15,5))\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Offer Type')\n",
    "plt.title('Offer viewed with Offer Type ');\n",
    "\n",
    "plt.subplot(133)\n",
    "offer_completed = data[data['offer-completed'] == 1].offer_type.value_counts()\n",
    "offer_completed.plot(kind='bar' , figsize=(15,5))\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Offer Type')\n",
    "plt.title('Offer completed received with Offer Type ');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For BOGO Offer :\n",
    "\n",
    "R = offer_received[1] \n",
    "V = offer_viewed[0] \n",
    "C = offer_completed[1] \n",
    "\n",
    "view_prop = V/R\n",
    "com_prop = C/R\n",
    "R , V , C , view_prop , com_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DISCOUNT Offer :\n",
    "\n",
    "R = offer_received[0] \n",
    "V = offer_viewed[1] \n",
    "C = offer_completed[0] \n",
    "\n",
    "view_prop = V/R\n",
    "com_prop = C/R\n",
    "R , V , C , view_prop , com_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation :\n",
    "\n",
    "- BOGO offers are highly demanding , 30499 users received BOGO offer  25449 viewed the offer and 15669 completed it .\n",
    "- the percentage of BOGO Offer viewer is 83 percent .\n",
    "- the percentage of DISCOUNT Offer viewer is 70 percent ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_received = data[data['offer-received'] == 1].offer_id.value_counts()\n",
    "offer_viewed = data[data['offer-viewed'] == 1].offer_id.value_counts()\n",
    "offer_completed = data[data['offer-completed'] == 1].offer_id.value_counts()\n",
    "\n",
    "offer_received , offer_viewed , offer_completed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(131)\n",
    "offer_received = data[data['offer-received'] == 1].offer_id.value_counts()\n",
    "offer_received.plot(kind='bar', figsize=(15,5))\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Offer Id ')\n",
    "plt.title('Offer received with Offer Id ');\n",
    "\n",
    "plt.subplot(132)\n",
    "offer_viewed = data[data['offer-viewed'] == 1].offer_id.value_counts()\n",
    "offer_viewed.plot(kind='bar' , figsize=(15,5))\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Offer Id')\n",
    "plt.title('Offer viewed with Offer Id ');\n",
    "\n",
    "plt.subplot(133)\n",
    "offer_completed = data[data['offer-completed'] == 1].offer_id.value_counts()\n",
    "offer_completed.plot(kind='bar' , figsize=(15,5))\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Offer Id')\n",
    "plt.title('Offer completed received with Offer Id ');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation :\n",
    "\n",
    "- evry offer_id received eual offers .\n",
    "- Viewing ratio decreased for some offer_ids like 0 , 6 , 7 , 5\n",
    "- Offer completed ration is quite decent ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['offer_type']=='bogo'].groupby('customer_id')['offer-received'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['offer_type']=='bogo'].groupby('customer_id')['offer-received'].count().hist();\n",
    "plt.title('BOGO Offer Received by User');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation :\n",
    "\n",
    "- the BOGO offer is received by quite decent amount of users ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['offer_type']=='informational'].groupby('customer_id')['offer-viewed'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['offer_type']=='informational'].groupby('customer_id')['offer-viewed'].count().hist();\n",
    "plt.title('Informational Offer Received by User');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation :\n",
    "\n",
    "- the ratio is 2 - 4 offer viewed is very high .\n",
    "- the difference is extremely high ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['offer_type']=='discount'].groupby('customer_id')['offer-completed'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['offer_type']=='discount'].groupby('customer_id')['offer-completed'].count().hist();\n",
    "plt.title('Discount Offer Received by User');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation :\n",
    "\n",
    "- the ratio od 2 - 4 times offer completed by the customer is very high ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Predictions :\n",
    "\n",
    "- apply one hot encoding for Gender column and Offer_type Column ( Pre Model Prepration )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = {'O': 0, 'M': 1, 'F': 2}\n",
    "data['gender'] = data['gender'].map(genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.offer_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers = {'bogo': 0, 'discount': 1, 'informational': 2}\n",
    "data['offer_type'] = data['offer_type'].map(offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['customer_id', 'event_id' , 'event' , 'became_member_on','offer-completed', 'offer-received',\n",
    "       'offer-viewed', 'transaction'], axis=1)\n",
    "Y = data['event_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape , Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling : \n",
    "\n",
    "#### Standardization & Normalization\n",
    "\n",
    "Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.\n",
    "\n",
    "Standardization is another scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name =['offer recieved', 'offer viewed', 'transaction', 'offer completed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into test and train sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.income = std.fit_transform(X_train.income.values.reshape(-1, 1))\n",
    "X_train.age = std.fit_transform(X_train.age.values.reshape(-1, 1))\n",
    "\n",
    "X_train.reset_index(inplace=True)\n",
    "X_train = X_train.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.income = std.transform(X_test.income.values.reshape(-1, 1))\n",
    "X_test.age = std.fit_transform(X_test.age.values.reshape(-1, 1))\n",
    "\n",
    "X_test.reset_index(inplace=True)\n",
    "X_test = X_test.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- converting the pandas dataframe into numpy array ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(keras.layers.Dense(6, activation='relu'))\n",
    "ann.add(keras.layers.Dense(6, activation='relu'))\n",
    "ann.add(keras.layers.Dense(4, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', \n",
    "            loss = 'sparse_categorical_crossentropy', \n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_history = ann.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.summary()       \n",
    "# Summary of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ann.history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)               # Y AXIS RANGE LIMIT \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Martrix :\n",
    "\n",
    "- evaluation can be done on the basis of accuracy obtained by the model and by Loss produced ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.evaluate(X_test , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "\n",
    "- the test accuracy is only 25% .\n",
    "- and the rate of accuracy remains constant throught the process .\n",
    "- this model needs some correction and improvement for better result ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement : Improving Prediction Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's create a new X dataframe with highly recommended features ,and highly dependent features .\n",
    "- more hidden layers .\n",
    "- more hidden units ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['customer_id', 'event_id' ,  'amount','event' , 'became_member_on','offer-completed', 'offer-received',\n",
    "       'offer-viewed','email', 'mobile', 'social', 'web', 'time','transaction', 'duration'], axis=1)\n",
    "Y = data['event_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape , Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.income = std.fit_transform(X_train.income.values.reshape(-1, 1))\n",
    "X_train.age = std.fit_transform(X_train.age.values.reshape(-1, 1))\n",
    "\n",
    "X_train.reset_index(inplace=True)\n",
    "X_train = X_train.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.income = std.transform(X_test.income.values.reshape(-1, 1))\n",
    "X_test.age = std.fit_transform(X_test.age.values.reshape(-1, 1))\n",
    "\n",
    "X_test.reset_index(inplace=True)\n",
    "X_test = X_test.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe into numpy array\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(keras.layers.Dense(32, input_dim=7, kernel_initializer = 'normal' ,activation='relu'))\n",
    "ann.add(keras.layers.Dense(15, kernel_initializer = 'normal' ,activation='relu'))\n",
    "ann.add(keras.layers.Dense(10, kernel_initializer = 'normal' ,activation='relu'))\n",
    "ann.add(keras.layers.Dense(6, kernel_initializer = 'normal' ,activation='relu'))\n",
    "ann.add(keras.layers.Dense(4, kernel_initializer = 'normal' ,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', \n",
    "            loss = 'sparse_categorical_crossentropy', \n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_history = ann.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=100 , verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ann.history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)               # Y AXIS RANGE LIMIT \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Martrix :\n",
    "\n",
    "- evaluation can be done on the basis of accuracy obtained by the model and by Loss produced ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.evaluate(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO PERFORM OF CHECK THE RESULT IN NEW DATA SET\n",
    "# AS WE DON'T HAVE NEW DATA SET , CREATE ONE FROM TEST DATA SET\n",
    "# HOW TO PREDICT THE PROBABILITY and CLASSES IN UNSEEN DATA\n",
    "\n",
    "\n",
    "x_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBABILITY OF EACH SET\n",
    "\n",
    "y_prob = ann.predict(x_new)\n",
    "y_prob.round(2)                        # RESULT IN 2 DECIMAL PLACE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASS OF EACH SET \n",
    "\n",
    "y_pred = ann.predict_classes(x_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(class_name)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "\n",
    "- there is no difference between the 1st and 2nd model .\n",
    "- the events are wrongly predicted as 'offer received'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion :\n",
    "\n",
    "- I found this project challenging, mainly due to the structure of the data in the transcript dataset.\n",
    "- Majority classes are performing well but the minorities are not.Problem of imbalanced dataset \n",
    "- Most of the events are wrongly predicted as 'offer received'; offer received is the most occuring event or class.\n",
    "\n",
    "**Main challenges and potential improvement:**\n",
    " Analysing and building the deep learning models .\n",
    " \n",
    " - The main goal I chose, was to build something practical the company could use make their choices more efficient.\n",
    " - But the results of the model seems like not so good . There is no change in rate of accuracy it remain constant ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References : \n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html\n",
    "- https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.merge.html\n",
    "- https://stackoverflow.com/questions/37600711/pandas-split-column-into-multiple-columns-by-comma\n",
    "- https://www.researchgate.net/post/Is_there_a_universal_method_rule_to_choose_the_activation_function_for_a_MLP_neural_network#:~:text=For%20binary%20classification%20(i.e.%20problems,entropy%20as%20the%20cost%20function.\n",
    "- https://stackoverflow.com/questions/55324762/the-added-layer-must-be-an-instance-of-class-layer-found-tensorflow-python-ke\n",
    "- https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
    "- https://www.tensorflow.org/tutorials/keras/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Starbucks_Capstone_notebook.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
